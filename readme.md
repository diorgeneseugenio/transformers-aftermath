# Transformers Aftermath: Current Research and Rising Trends

This repository provides research data for the review article: "Transformers Aftermath: Current Research and Rising Trends".

## Abstract

Natural Language Processing is a major field of research on artificial intelligence, enabling tasks such as translation, text generation, and human-machine dialog.
Recently, it achieved impressive milestones through the use of attention mechanisms.
In particular, self-attention became norm after the work on Transformers was published, by enabling model parallelization and the mapping of longer-term dependencies between words and sentences.
From Recurrent Neural Networks to Transformers, the community proposed a huge volume of remarkable solutions during the last 2 years.
Despite the success, attention has its own limitations regarding meaning and commonsense reasoning.
%In other words, it is unable to understand the text.
Most reviewed methods use statistical knowledge to infer, for example, the most likely next word in a sentence given its context, without encoding the meaning behind it.
Through a broad review of the recent literature, we identify research trends and evince the most promising research paths.
Augmenting the models with prior facts and external knowledge are the key approaches towards "meaningful" modeling of natural language.
Consequently, knowledge distillation and multi-task training procedures are leveraging the state-of-the-art upon new milestones.